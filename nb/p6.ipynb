{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad81a6d-1fed-499c-9c95-fb69e89a7f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load        Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.21.0.4  222.2 KiB   16      100.0%            739395b2-9b2a-4828-a1a2-a85a7e358b24  rack1\n",
      "UN  172.21.0.2  249.78 KiB  16      100.0%            d9d860d3-d1f1-4282-85f4-efd30b5b1258  rack1\n",
      "UN  172.21.0.3  207.45 KiB  16      100.0%            b6057742-477a-4263-8869-1dc8926cb85e  rack1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nodetool status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a20b2c-e91a-43ec-b803-5ab403442b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the Cassandra cluster\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['p6-db-1', 'p6-db-2', 'p6-db-3'])\n",
    "cass = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d45fbfa-9090-4390-aede-7cd3289acfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE weather.stations (\n",
      "    id text,\n",
      "    date date,\n",
      "    name text static,\n",
      "    state text,\n",
      "    record station_record,\n",
      "    PRIMARY KEY (id, date)\n",
      ") WITH CLUSTERING ORDER BY (date ASC)\n",
      "    AND additional_write_policy = '99p'\n",
      "    AND bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND cdc = false\n",
      "    AND comment = ''\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND memtable = 'default'\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND extensions = {}\n",
      "    AND gc_grace_seconds = 864000\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 0\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair = 'BLOCKING'\n",
      "    AND speculative_retry = '99p';\n"
     ]
    }
   ],
   "source": [
    "#q1\n",
    "#drop a weather keyspace if it already exists\n",
    "cass.execute(\"drop keyspace if exists weather;\")\n",
    "#create a weather keyspace with 3x replication\n",
    "cass.execute(\"create keyspace weather with replication={'class': 'SimpleStrategy', 'replication_factor': 3};\")\n",
    "#inside weather, create a station_record type containing two ints: tmin and tmax\n",
    "cass.execute(\"\"\"\n",
    "CREATE TYPE\n",
    "weather.station_record (\n",
    "    tmin int,\n",
    "    tmax int\n",
    ")\n",
    "\"\"\")\n",
    "#inside weather, create a stations table\n",
    "cass.execute(\"\"\"\n",
    "CREATE TABLE weather.stations (\n",
    "    id text,\n",
    "    name TEXT STATIC,\n",
    "    date date,\n",
    "    record station_record,\n",
    "    state TEXT,\n",
    "    PRIMARY KEY (id,date)\n",
    ") WITH CLUSTERING ORDER BY (date ASC)\n",
    "\"\"\")\n",
    "\n",
    "print(cass.execute(\"describe table weather.stations \").one().create_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4517e-71a1-4465-b7f3-fc51b34df568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c14cbff-ca2d-47d4-88fa-52dd1125fd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-fa0ecdf7-d8c6-4efc-88f4-a25e5603acf7;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.4.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      ":: resolution report :: resolve 1724ms :: artifacts dl 31ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.4.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   0   |   0   |   0   ||   18  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-fa0ecdf7-d8c6-4efc-88f4-a25e5603acf7\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 18 already retrieved (0kB/22ms)\n",
      "23/11/21 00:50:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#Create a local Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"p6\")\n",
    "         .config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.4.0')\n",
    "         .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c0e3fe-3ad3-49e8-b1be-ae0e4d8194a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext # for interacting directly with RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "748c6acf-3a0e-4247-85f6-73e09d4e1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a67866-082b-46af-acb6-5a19b2085c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.text(\"ghcnd-stations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b03d9d1-8142-4b66-aad7-329ad064b966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pandas_df=df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1295e142-505e-4ee9-b25e-38e11402cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df[\"station\"] = pandas_df[\"value\"].str[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c3445d5-2e48-4b49-bb27-a65f0d1dc5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c89aa78-ea54-4645-bc84-ee1ca068b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>station</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US1WIAD0002  43.9544  -89.8096  294.4 WI ADAMS...</td>\n",
       "      <td>US1WIAD0002</td>\n",
       "      <td>WI ADAMS 0.4 E</td>\n",
       "      <td>ADAMS 0.4 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US1WIAD0005  44.2053  -89.8480  305.7 WI NEKOO...</td>\n",
       "      <td>US1WIAD0005</td>\n",
       "      <td>WI NEKOOSA 8.0 SSE</td>\n",
       "      <td>NEKOOSA 8.0 SSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US1WIAD0006  43.8858  -89.7259  307.8 WI GRAND...</td>\n",
       "      <td>US1WIAD0006</td>\n",
       "      <td>WI GRAND MARSH 1.0 W</td>\n",
       "      <td>GRAND MARSH 1.0 W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US1WIAD0008  43.8611  -89.7163  310.0 WI GRAND...</td>\n",
       "      <td>US1WIAD0008</td>\n",
       "      <td>WI GRAND MARSH 1.9 SSW</td>\n",
       "      <td>GRAND MARSH 1.9 SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US1WIAD0010  43.7864  -89.6417  293.8 WI OXFOR...</td>\n",
       "      <td>US1WIAD0010</td>\n",
       "      <td>WI OXFORD 4.0 W</td>\n",
       "      <td>OXFORD 4.0 W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>USW00094930  43.9333  -90.2667  280.1 WI VOLK ...</td>\n",
       "      <td>USW00094930</td>\n",
       "      <td>WI VOLK FLD ANG</td>\n",
       "      <td>VOLK FLD ANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>USW00094940  43.9667  -90.7333  252.7 WI SPART...</td>\n",
       "      <td>USW00094940</td>\n",
       "      <td>WI SPARTA FT MCCOY</td>\n",
       "      <td>SPARTA FT MCCOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>USW00094973  46.0303  -91.4425  368.8 WI HAYWA...</td>\n",
       "      <td>USW00094973</td>\n",
       "      <td>WI HAYWARD MUNI AP</td>\n",
       "      <td>HAYWARD MUNI AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>USW00094985  44.6378  -90.1875  381.6 WI MARSH...</td>\n",
       "      <td>USW00094985</td>\n",
       "      <td>WI MARSHFIELD MUNI AP</td>\n",
       "      <td>MARSHFIELD MUNI AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>USW00094994  43.1561  -90.6775  203.0 WI BOSCO...</td>\n",
       "      <td>USW00094994</td>\n",
       "      <td>WI BOSCOBEL AP</td>\n",
       "      <td>BOSCOBEL AP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  value      station  \\\n",
       "0     US1WIAD0002  43.9544  -89.8096  294.4 WI ADAMS...  US1WIAD0002   \n",
       "1     US1WIAD0005  44.2053  -89.8480  305.7 WI NEKOO...  US1WIAD0005   \n",
       "2     US1WIAD0006  43.8858  -89.7259  307.8 WI GRAND...  US1WIAD0006   \n",
       "3     US1WIAD0008  43.8611  -89.7163  310.0 WI GRAND...  US1WIAD0008   \n",
       "4     US1WIAD0010  43.7864  -89.6417  293.8 WI OXFOR...  US1WIAD0010   \n",
       "...                                                 ...          ...   \n",
       "1308  USW00094930  43.9333  -90.2667  280.1 WI VOLK ...  USW00094930   \n",
       "1309  USW00094940  43.9667  -90.7333  252.7 WI SPART...  USW00094940   \n",
       "1310  USW00094973  46.0303  -91.4425  368.8 WI HAYWA...  USW00094973   \n",
       "1311  USW00094985  44.6378  -90.1875  381.6 WI MARSH...  USW00094985   \n",
       "1312  USW00094994  43.1561  -90.6775  203.0 WI BOSCO...  USW00094994   \n",
       "\n",
       "                                         STATE  \\\n",
       "0      WI ADAMS 0.4 E                            \n",
       "1      WI NEKOOSA 8.0 SSE                        \n",
       "2      WI GRAND MARSH 1.0 W                      \n",
       "3      WI GRAND MARSH 1.9 SSW                    \n",
       "4      WI OXFORD 4.0 W                           \n",
       "...                                        ...   \n",
       "1308   WI VOLK FLD ANG                           \n",
       "1309   WI SPARTA FT MCCOY                        \n",
       "1310   WI HAYWARD MUNI AP                        \n",
       "1311   WI MARSHFIELD MUNI AP                     \n",
       "1312   WI BOSCOBEL AP                            \n",
       "\n",
       "                                               NAME  \n",
       "0      ADAMS 0.4 E                                   \n",
       "1      NEKOOSA 8.0 SSE                               \n",
       "2      GRAND MARSH 1.0 W                             \n",
       "3      GRAND MARSH 1.9 SSW                           \n",
       "4      OXFORD 4.0 W                                  \n",
       "...                                             ...  \n",
       "1308   VOLK FLD ANG                                  \n",
       "1309   SPARTA FT MCCOY                               \n",
       "1310   HAYWARD MUNI AP                               \n",
       "1311   MARSHFIELD MUNI AP                            \n",
       "1312   BOSCOBEL AP                                   \n",
       "\n",
       "[1313 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.withColumn(\"station\", expr(\"substring(value, 0, 11)\")).withColumn(\n",
    "     \"STATE\",expr(\"substring(value,38,40)\")).withColumn(\n",
    "     \"NAME\",expr(\"substring(value, 41,71)\"))\n",
    "df2\n",
    "df2=df2.filter(col(\"STATE\").like(\"% WI %\")).filter(col(\"station\").like(\"%US%\"))\n",
    "df2.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2db2532-d50e-4deb-85c0-59dd54dc1fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313\n"
     ]
    }
   ],
   "source": [
    "#Filter your results to the state of Wisconsin, collect the rows in your notebook so you can loop over them,\n",
    "#and do an INSERT into your weather.stations table for each station ID and name.\n",
    "\n",
    "# i=0\n",
    "# for row in df2.collect():\n",
    "#     station_WI = row[\"station\"]\n",
    "#     name_WI = row[\"NAME\"]\n",
    "    \n",
    "#     # print(i)\n",
    "#     # i+=1\n",
    "#     # if(i==684 or i==685):\n",
    "#     #     print(station_WI)\n",
    "#     #     print(name_WI)\n",
    "#     if \"'\" in name_WI or \"'\" in station_WI:\n",
    "#         insert_query = f'INSERT INTO weather.stations (id, name) VALUES (\"{station_WI}\", \"{name_WI}\")'\n",
    "#     else:\n",
    "#         insert_query = f\"INSERT INTO weather.stations (id, name) VALUES ('{station_WI}', '{name_WI}')\"\n",
    "#     cass.execute(insert_query)\n",
    "insert_query = \"INSERT INTO weather.stations (id, name) VALUES (?, ?)\"\n",
    "prepared_statement = cass.prepare(insert_query)\n",
    "i=0\n",
    "for row in df2.collect():\n",
    "    station_WI = row[\"station\"]\n",
    "    name_WI = row[\"NAME\"]\n",
    "    values = (station_WI, name_WI)\n",
    "    cass.execute(prepared_statement, values)\n",
    "    i+=1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1355166c-552d-4820-9de9-5e196da94685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0   1313"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(cass.execute(\n",
    "    \"\"\"\n",
    "    SELECT * FROM weather.stations\n",
    "    \"\"\"\n",
    "))\n",
    "pd.DataFrame(cass.execute(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(*) FROM weather.stations\n",
    "    \"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a04cb620-3e0c-43a1-9264-d0c9b8b0fa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MADISON DANE CO RGNL AP                72641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name\n",
       "0   MADISON DANE CO RGNL AP                72641"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cass.execute(\n",
    "    \"\"\"\n",
    "    SELECT name FROM weather.stations\n",
    "    WHERE id = 'USW00014837'\n",
    "    \"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4b5bb-3a01-457e-8a99-ec1bbe4fcf83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
