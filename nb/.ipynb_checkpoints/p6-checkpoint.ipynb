{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cad81a6d-1fed-499c-9c95-fb69e89a7f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load        Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.21.0.4  203.86 KiB  16      100.0%            739395b2-9b2a-4828-a1a2-a85a7e358b24  rack1\n",
      "UN  172.21.0.2  201.69 KiB  16      100.0%            d9d860d3-d1f1-4282-85f4-efd30b5b1258  rack1\n",
      "UN  172.21.0.3  190.49 KiB  16      100.0%            b6057742-477a-4263-8869-1dc8926cb85e  rack1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nodetool status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "03a20b2c-e91a-43ec-b803-5ab403442b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the Cassandra cluster\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['p6-db-1', 'p6-db-2', 'p6-db-3'])\n",
    "cass = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3d45fbfa-9090-4390-aede-7cd3289acfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE weather.stations (\n",
      "    id text,\n",
      "    date date,\n",
      "    name text static,\n",
      "    state text,\n",
      "    record station_record,\n",
      "    PRIMARY KEY (id, date)\n",
      ") WITH CLUSTERING ORDER BY (date ASC)\n",
      "    AND additional_write_policy = '99p'\n",
      "    AND bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND cdc = false\n",
      "    AND comment = ''\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND memtable = 'default'\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND extensions = {}\n",
      "    AND gc_grace_seconds = 864000\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 0\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair = 'BLOCKING'\n",
      "    AND speculative_retry = '99p';\n"
     ]
    }
   ],
   "source": [
    "#q1\n",
    "#drop a weather keyspace if it already exists\n",
    "cass.execute(\"drop keyspace if exists weather;\")\n",
    "#create a weather keyspace with 3x replication\n",
    "cass.execute(\"create keyspace weather with replication={'class': 'SimpleStrategy', 'replication_factor': 3};\")\n",
    "#inside weather, create a station_record type containing two ints: tmin and tmax\n",
    "cass.execute(\"\"\"\n",
    "CREATE TYPE\n",
    "weather.station_record (\n",
    "    tmin int,\n",
    "    tmax int\n",
    ")\n",
    "\"\"\")\n",
    "#inside weather, create a stations table\n",
    "cass.execute(\"\"\"\n",
    "CREATE TABLE weather.stations (\n",
    "    id text,\n",
    "    name TEXT STATIC,\n",
    "    date date,\n",
    "    record station_record,\n",
    "    state TEXT,\n",
    "    PRIMARY KEY (id,date)\n",
    ") WITH CLUSTERING ORDER BY (date ASC)\n",
    "\"\"\")\n",
    "\n",
    "print(cass.execute(\"describe table weather.stations \").one().create_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5c14cbff-ca2d-47d4-88fa-52dd1125fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a local Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"p6\")\n",
    "         .config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.4.0')\n",
    "         .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "38c0e3fe-3ad3-49e8-b1be-ae0e4d8194a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext # for interacting directly with RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "748c6acf-3a0e-4247-85f6-73e09d4e1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "94a67866-082b-46af-acb6-5a19b2085c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.text(\"ghcnd-stations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9b03d9d1-8142-4b66-aad7-329ad064b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df=df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1295e142-505e-4ee9-b25e-38e11402cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df[\"station\"] = pandas_df[\"value\"].str[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8c3445d5-2e48-4b49-bb27-a65f0d1dc5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5c89aa78-ea54-4645-bc84-ee1ca068b05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>station</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US1WICB0008  43.6324  -89.7672  285.9 WI WISCO...</td>\n",
       "      <td>US1WICB0008</td>\n",
       "      <td>WI WISCONSIN DELLS 0.7 NE</td>\n",
       "      <td>WISCONSIN DELLS 0.7 NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US1WIJN0005  43.6465  -89.7963  256.3 WI WISCO...</td>\n",
       "      <td>US1WIJN0005</td>\n",
       "      <td>WI WISCONSIN DELLS 1.7 NNW</td>\n",
       "      <td>WISCONSIN DELLS 1.7 NNW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US1WIWD0002  44.3382  -89.7820  311.2 WI WISCO...</td>\n",
       "      <td>US1WIWD0002</td>\n",
       "      <td>WI WISCONSIN RAPIDS 4.6 SSE</td>\n",
       "      <td>WISCONSIN RAPIDS 4.6 SSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US1WIWD0009  44.3608  -89.7747  313.6 WI WISCO...</td>\n",
       "      <td>US1WIWD0009</td>\n",
       "      <td>WI WISCONSIN RAPIDS 3.7 SE</td>\n",
       "      <td>WISCONSIN RAPIDS 3.7 SE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00479319  43.6072  -89.7633  253.9 WI WISCO...</td>\n",
       "      <td>USC00479319</td>\n",
       "      <td>WI WISCONSIN DELLS WWTP</td>\n",
       "      <td>WISCONSIN DELLS WWTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>USC00479335  44.3881  -89.8056  314.9 WI WISCO...</td>\n",
       "      <td>USC00479335</td>\n",
       "      <td>WI WISCONSIN RAPIDS</td>\n",
       "      <td>WISCONSIN RAPIDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>USR0000WANT  45.1500  -89.1500  456.9 WI ANTIG...</td>\n",
       "      <td>USR0000WANT</td>\n",
       "      <td>WI ANTIGO WISCONSIN</td>\n",
       "      <td>ANTIGO WISCONSIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>USR0000WAUG  44.6981  -91.1342  295.7 WI AUGUS...</td>\n",
       "      <td>USR0000WAUG</td>\n",
       "      <td>WI AUGUSTA WISCONSIN</td>\n",
       "      <td>AUGUSTA WISCONSIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>USR0000WBAR  46.4000  -91.5000  368.8 WI BARNE...</td>\n",
       "      <td>USR0000WBAR</td>\n",
       "      <td>WI BARNES WISCONSIN</td>\n",
       "      <td>BARNES WISCONSIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USR0000WBRF  44.3003  -90.8350  255.4 WI BLACK...</td>\n",
       "      <td>USR0000WBRF</td>\n",
       "      <td>WI BLACK RIVER FALLS WISCONSIN</td>\n",
       "      <td>BLACK RIVER FALLS WISCONSIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USR0000WDDG  43.1000  -90.0000  384.0 WI DODGE...</td>\n",
       "      <td>USR0000WDDG</td>\n",
       "      <td>WI DODGEVILLE WISCONSIN</td>\n",
       "      <td>DODGEVILLE WISCONSIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>USR0000WGLI  46.1400  -90.0000  472.4 WI GLIDD...</td>\n",
       "      <td>USR0000WGLI</td>\n",
       "      <td>WI GLIDDEN WISCONSIN</td>\n",
       "      <td>GLIDDEN WISCONSIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>USW00004826  44.3592  -89.8369  309.4 WI WISCO...</td>\n",
       "      <td>USW00004826</td>\n",
       "      <td>WI WISCONSIN RAPIDS ALEXANDER FLD</td>\n",
       "      <td>WISCONSIN RAPIDS ALEXANDER FLD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                value      station  \\\n",
       "0   US1WICB0008  43.6324  -89.7672  285.9 WI WISCO...  US1WICB0008   \n",
       "1   US1WIJN0005  43.6465  -89.7963  256.3 WI WISCO...  US1WIJN0005   \n",
       "2   US1WIWD0002  44.3382  -89.7820  311.2 WI WISCO...  US1WIWD0002   \n",
       "3   US1WIWD0009  44.3608  -89.7747  313.6 WI WISCO...  US1WIWD0009   \n",
       "4   USC00479319  43.6072  -89.7633  253.9 WI WISCO...  USC00479319   \n",
       "5   USC00479335  44.3881  -89.8056  314.9 WI WISCO...  USC00479335   \n",
       "6   USR0000WANT  45.1500  -89.1500  456.9 WI ANTIG...  USR0000WANT   \n",
       "7   USR0000WAUG  44.6981  -91.1342  295.7 WI AUGUS...  USR0000WAUG   \n",
       "8   USR0000WBAR  46.4000  -91.5000  368.8 WI BARNE...  USR0000WBAR   \n",
       "9   USR0000WBRF  44.3003  -90.8350  255.4 WI BLACK...  USR0000WBRF   \n",
       "10  USR0000WDDG  43.1000  -90.0000  384.0 WI DODGE...  USR0000WDDG   \n",
       "11  USR0000WGLI  46.1400  -90.0000  472.4 WI GLIDD...  USR0000WGLI   \n",
       "12  USW00004826  44.3592  -89.8369  309.4 WI WISCO...  USW00004826   \n",
       "\n",
       "                                       STATE  \\\n",
       "0    WI WISCONSIN DELLS 0.7 NE                 \n",
       "1    WI WISCONSIN DELLS 1.7 NNW                \n",
       "2    WI WISCONSIN RAPIDS 4.6 SSE               \n",
       "3    WI WISCONSIN RAPIDS 3.7 SE                \n",
       "4    WI WISCONSIN DELLS WWTP                   \n",
       "5    WI WISCONSIN RAPIDS                       \n",
       "6    WI ANTIGO WISCONSIN                       \n",
       "7    WI AUGUSTA WISCONSIN                      \n",
       "8    WI BARNES WISCONSIN                       \n",
       "9    WI BLACK RIVER FALLS WISCONSIN            \n",
       "10   WI DODGEVILLE WISCONSIN                   \n",
       "11   WI GLIDDEN WISCONSIN                      \n",
       "12   WI WISCONSIN RAPIDS ALEXANDER FLD         \n",
       "\n",
       "                                             NAME  \n",
       "0    WISCONSIN DELLS 0.7 NE                        \n",
       "1    WISCONSIN DELLS 1.7 NNW                       \n",
       "2    WISCONSIN RAPIDS 4.6 SSE                      \n",
       "3    WISCONSIN RAPIDS 3.7 SE                       \n",
       "4    WISCONSIN DELLS WWTP                          \n",
       "5    WISCONSIN RAPIDS                              \n",
       "6    ANTIGO WISCONSIN                              \n",
       "7    AUGUSTA WISCONSIN                             \n",
       "8    BARNES WISCONSIN                              \n",
       "9    BLACK RIVER FALLS WISCONSIN                   \n",
       "10   DODGEVILLE WISCONSIN                          \n",
       "11   GLIDDEN WISCONSIN                             \n",
       "12   WISCONSIN RAPIDS ALEXANDER FLD                "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.withColumn(\"station\", expr(\"substring(value, 0, 11)\")).withColumn(\n",
    "     \"STATE\",expr(\"substring(value,38,40)\")).withColumn(\n",
    "     \"NAME\",expr(\"substring(value, 41,71)\"))\n",
    "df2\n",
    "df2=df2.filter(col(\"STATE\").like(\"%WISCONSIN%\"))\n",
    "df2.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e2db2532-d50e-4deb-85c0-59dd54dc1fa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column or function parameter with name `US1WICB0008` cannot be resolved. ; line 1 pos 37;\n'InsertIntoStatement 'UnresolvedRelation [weather, stations], [], false, false, false\n+- 'UnresolvedInlineTable [col1, col2], [['US1WICB0008,  WISCONSIN DELLS 0.7 NE                      ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m name_WI\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m sql_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSERT INTO weather.stations VALUES (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstation_WI\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_WI\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#spark.sql(f\"INSERT INTO weather.stations VALUES ({station_WI},'{name_WI}')\")\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py:1440\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1439\u001b[0m     litArgs \u001b[38;5;241m=\u001b[39m {k: _to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column or function parameter with name `US1WICB0008` cannot be resolved. ; line 1 pos 37;\n'InsertIntoStatement 'UnresolvedRelation [weather, stations], [], false, false, false\n+- 'UnresolvedInlineTable [col1, col2], [['US1WICB0008,  WISCONSIN DELLS 0.7 NE                      ]]\n"
     ]
    }
   ],
   "source": [
    "#Filter your results to the state of Wisconsin, collect the rows in your notebook so you can loop over them,\n",
    "#and do an INSERT into your weather.stations table for each station ID and name.\n",
    "for row in df2.collect():\n",
    "    station_WI=row[\"station\"]\n",
    "    name_WI=row[\"NAME\"]\n",
    "    sql_query=f\"INSERT INTO weather.stations VALUES ({station_WI},'{name_WI}')\"\n",
    "    spark.sql(sql_query)\n",
    "    #spark.sql(f\"INSERT INTO weather.stations VALUES ({station_WI},'{name_WI}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8373ae46-2d9e-49d9-b6a3-30dfda0a2bb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `weather`.`stations` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 12;\n'InsertIntoStatement 'UnresolvedRelation [weather, stations], [], false, false, false\n+- LocalRelation [col1#174, col2#175]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[147], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m sql_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSERT INTO weather.stations VALUES (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstation_WI\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_WI\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Insert into the MySQL table\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py:1440\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1439\u001b[0m     litArgs \u001b[38;5;241m=\u001b[39m {k: _to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `weather`.`stations` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 12;\n'InsertIntoStatement 'UnresolvedRelation [weather, stations], [], false, false, false\n+- LocalRelation [col1#174, col2#175]\n"
     ]
    }
   ],
   "source": [
    "for row in df2.collect():\n",
    "    station_WI = row[\"station\"]\n",
    "    name_WI = row[\"NAME\"]\n",
    "\n",
    "    # Use proper string formatting and handle special characters\n",
    "    sql_query = f\"INSERT INTO weather.stations VALUES ('{station_WI}', '{name_WI}')\"\n",
    "\n",
    "    # Insert into the MySQL table\n",
    "    spark.sql(sql_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "376c2dd2-0e81-4034-ae91-782ebc2f6b14",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxException",
     "evalue": "<Error from server: code=2000 [Syntax error in CQL query] message=\"line 3:4 no viable alternative at input 'SELECT' (    INSERT INTO weather.stations     [SELECT]...)\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSyntaxException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43;03m    INSERT INTO weather.stations \u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43;03m    SELECT * FROM df2\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m    \n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/cassandra/cluster.py:2637\u001b[0m, in \u001b[0;36mcassandra.cluster.Session.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/cassandra/cluster.py:4920\u001b[0m, in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mSyntaxException\u001b[0m: <Error from server: code=2000 [Syntax error in CQL query] message=\"line 3:4 no viable alternative at input 'SELECT' (    INSERT INTO weather.stations     [SELECT]...)\">"
     ]
    }
   ],
   "source": [
    "cass.execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO weather.stations \n",
    "    SELECT * FROM df2\n",
    "    \"\"\"\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2024c5bb-1277-46a1-b1d5-cb3b1697162e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.protocol:Server warning: Aggregation query used without partition key\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f2e458239a0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\n",
    "    \"\"\"\n",
    "    SELECT COUNT(*) FROM weather.stations\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff22cb-d4c2-4942-89cd-4ae65468a9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
